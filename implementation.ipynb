{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b819698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import lax\n",
    "import jax\n",
    "from jax import random\n",
    "\n",
    "import torch\n",
    "import torch.autograd.functional as TF\n",
    "torch_jvp = TF.jvp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05bc7a9",
   "metadata": {},
   "source": [
    "## Cases\n",
    "$$\n",
    "\\newcommand{\\tr}{{\\mathrm{tr}}}\n",
    "\\newcommand{\\d}{{\\mathrm{d}}}\n",
    "\\newcommand{\\A}{{\\mathbf{A}}}\n",
    "\\newcommand{\\U}{{\\mathbf{U}}}\n",
    "\\newcommand{\\S}{{\\mathbf{S}}}\n",
    "\\newcommand{\\V}{{\\mathbf{V}}}\n",
    "\\newcommand{\\F}{{\\mathbf{F}}}\n",
    "\\newcommand{\\I}{{\\mathbf{I}}}\n",
    "\\newcommand{\\dA}{{\\d\\A}}\n",
    "\\newcommand{\\dU}{{\\d\\U}}\n",
    "\\newcommand{\\dS}{{\\d\\S}}\n",
    "\\newcommand{\\dV}{{\\d\\V}}\n",
    "\\newcommand{\\Ut}{{\\U^{\\top}}}\n",
    "\\newcommand{\\Vt}{{\\V^{\\top}}}\n",
    "\\newcommand{\\Vh}{{\\V^{H}}}\n",
    "\\newcommand{\\dAt}{{\\dA^{\\top}}}\n",
    "\\newcommand{\\dVt}{{\\dV^{\\top}}}\n",
    "\\newcommand{\\gA}{{\\overline{\\A}}}\n",
    "\\newcommand{\\gAt}{{\\gA^{\\top}}}\n",
    "\\newcommand{\\gU}{{\\overline{\\U}}}\n",
    "\\newcommand{\\gUt}{{\\gU^{\\top}}}\n",
    "\\newcommand{\\gS}{{\\overline{\\S}}}\n",
    "\\newcommand{\\gSt}{{\\gS^{\\top}}}\n",
    "\\newcommand{\\gV}{{\\overline{\\V}}}\n",
    "\\newcommand{\\gVt}{{\\gV^{\\top}}}\n",
    "$$\n",
    "The derivative of the SVD operation is determined by\n",
    "\n",
    "1. Computing the full SVD vs the \"thin\"/\"partial\" SVD\n",
    "2. Computing the complete factorization $\\U\\S\\Vh$ vs computing just the singular values $\\S$\n",
    "3. complex vs real inputs\n",
    "\n",
    "These cases create 8 different cases for the SVD derivative each with separate differential formulas for forward mode AD update and adjoint formula for the reverse mode AD update.\n",
    "\n",
    "## Numerical instability\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac90ffc",
   "metadata": {},
   "source": [
    "## Real valued partial SVD\n",
    "\n",
    "Reference: https://j-towns.github.io/papers/svd-derivative.pdf\n",
    "\n",
    "### Forward mode\n",
    "\n",
    "The differential formulas $\\dU$, $\\dS$, and $\\dV$ in terms of $\\dA$, $\\U$, $\\S$, and $\\V$ are found from the chain rule (TODO check this from the differential formula).\n",
    "\n",
    "##### Chain rule\n",
    "\n",
    "$\\dA = \\dU \\S \\Vt + \\U \\dS \\Vt + \\U \\S \\dVt$\n",
    "\n",
    "##### Differential formulas\n",
    "\n",
    "$\\dU = \\U ( \\F \\circ [\\Ut \\dA \\V \\S + \\S \\Vt \\dAt \\U] ) + (\\I_m - \\U \\Ut ) \\dA \\V \\S^{-1}$\n",
    "\n",
    "$\\dS = \\I_k \\circ [\\Ut \\dA \\V]$\n",
    "\n",
    "$\\dV = \\V (\\F \\circ [\\S \\Ut \\dA \\V + \\Vt \\dAt \\U \\S]) + (\\I_n - \\V \\Vt) \\dAt \\U \\S^{-1}$\n",
    "\n",
    "where\n",
    "\n",
    "$F_{ij} = \\frac{1}{s_j^2 - s_i^s}, i \\neq j$\n",
    "\n",
    "$F_{ij} = 0$ otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56584cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_jvp_real_valued_partial(A, dA):    \n",
    "    U, S_vals, Vt = jnp.linalg.svd(A, compute_uv=True, full_matrices=False)\n",
    "\n",
    "    S = jnp.diag(S_vals)\n",
    "    Ut = U.T\n",
    "    V = Vt.T\n",
    "    dAt = dA.T\n",
    "\n",
    "    k = S.shape[0]\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "\n",
    "    I_k = jnp.eye(k)\n",
    "    I_m = jnp.eye(m)\n",
    "    I_n = jnp.eye(n)\n",
    "\n",
    "    S_inv = jnp.linalg.inv(S)\n",
    "\n",
    "    F_ = F(S_vals, k)\n",
    "\n",
    "    dU = U @ (F_ * ((Ut @ dA @ V @ S) + (S @ Vt @ dAt @ U))) + ((I_m - U @ Ut) @ dA @ V @ S_inv)\n",
    "    \n",
    "    # Note that the `I_k *` is extraneous. It zeros out the rest of the matrix besides the diagonal.\n",
    "    # We only return `dS_vals` which takes only the diagonal of `dS` anyway. \n",
    "    dS = I_k * (Ut @ dA @ V)\n",
    "    dS_vals = jnp.diagonal(dS)\n",
    "    \n",
    "    dV = V @ (F_ * (S @ Ut @ dA @ V + Vt @ dAt @ U @ S)) + (I_n - V @ Vt) @ dAt @ U @ S_inv\n",
    "    \n",
    "    return (U, S_vals, Vt), (dU, dS_vals, dV.T)\n",
    "\n",
    "def F(S_vals, k):\n",
    "    F_i_j = lambda i, j: lax.cond(i == j, lambda: 0., lambda: 1 / (S_vals[j]**2 - S_vals[i]**2))\n",
    "    F_fun = jax.vmap(jax.vmap(F_i_j, (None, 0)), (0, None))\n",
    "\n",
    "    indices = jnp.arange(k)\n",
    "    F_ = F_fun(indices, indices)\n",
    "    \n",
    "    return F_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b00e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_svd_uv(a, b):\n",
    "    (U, S, Vt), (dU, dS, dVt) = a\n",
    "    (U_, S_, Vt_), (dU_, dS_, dVt_) = b\n",
    "    \n",
    "    assert_allclose(U, U_)\n",
    "    assert_allclose(S, S_)\n",
    "    assert_allclose(Vt, Vt_)\n",
    "    assert_allclose(dU, dU_)\n",
    "    assert_allclose(dS, dS_)\n",
    "    assert_allclose(dVt, dVt_)\n",
    "\n",
    "def assert_allclose(l, r):\n",
    "    assert(jnp.allclose(jnp.array(l), jnp.array(r), atol=1e-05))\n",
    "        \n",
    "def jax_real_valued_partial(A, dA):\n",
    "    A = jnp.array(A)\n",
    "    dA = jnp.array(dA)\n",
    "    \n",
    "    return jax.jvp(\n",
    "        lambda A: jnp.linalg.svd(A, compute_uv=True, full_matrices=False), \n",
    "        (A,), \n",
    "        (dA,)\n",
    "    )\n",
    "\n",
    "def pytorch_real_valued_partial(A, dA):\n",
    "    A = torch.tensor(A)\n",
    "    dA = torch.tensor(dA)\n",
    "    \n",
    "    return torch_jvp(lambda A: torch.linalg.svd(A, full_matrices=False), A, dA)\n",
    "    \n",
    "def check_real_valued_partial(A, dA):\n",
    "    jax_res = jax_real_valued_partial(A, dA)\n",
    "    torch_res = pytorch_real_valued_partial(A, dA)\n",
    "    res = svd_jvp_real_valued_partial(jnp.array(A), jnp.array(dA))\n",
    "    \n",
    "    # example == jax == torch\n",
    "    assert_svd_uv(jax_res, torch_res)\n",
    "    assert_svd_uv(jax_res, res)\n",
    "\n",
    "def check_real_valued_partials():\n",
    "    key = random.PRNGKey(0)\n",
    "    \n",
    "    for m in range(3, 11):\n",
    "        for n in range(3, 11):\n",
    "            key, subkey = random.split(key)\n",
    "            \n",
    "            A = random.normal(subkey, (m, n))\n",
    "            dA = jnp.ones_like(A)\n",
    "            \n",
    "            A = A.tolist()\n",
    "            dA = dA.tolist()\n",
    "            \n",
    "            check_real_valued_partial(A, dA)\n",
    "\n",
    "\n",
    "check_real_valued_partials()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffc7a36",
   "metadata": {},
   "source": [
    "### Reverse mode\n",
    "\n",
    "##### Chain rule\n",
    "\n",
    "$ \\tr(\\gAt \\dA) = \\tr(\\gUt \\dU) + \\tr(\\gSt \\dS) + \\tr(\\gVt \\dV) $\n",
    "\n",
    "##### Gradient formula\n",
    "\n",
    "The formula for A's gradient has terms $\\mathrm{term}_U$, $\\mathrm{term}_S$, and $\\mathrm{term}_V$ found from the respective trace terms in the chain rule\n",
    "\n",
    "$\\gA = \\mathrm{term}_U + \\mathrm{term}_S + \\mathrm{term}_V$\n",
    "\n",
    "$\\mathrm{term}_U = [\\U (\\F \\circ [\\Ut \\gU - \\gUt \\U]) \\S + (\\I_m - \\U \\Ut) \\gU \\S^{-1} ] \\Vt$\n",
    "\n",
    "$\\mathrm{term}_S = \\U (\\I_k \\circ \\gS ) \\Vt$\n",
    "\n",
    "$\\mathrm{term}_V = \\U [\\S (\\F \\circ [\\Vt \\gV - \\gVt \\V]) \\Vt + \\S^{-1} \\gVt (\\I_n - \\V \\Vt)]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32dbfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_vjp_real_valued_partial(A, U, S_vals, Vt, gU, gS_vals, gVt):\n",
    "    S = jnp.diag(S_vals)\n",
    "    gS = jnp.diag(gS_vals)\n",
    "    \n",
    "    k = S.shape[0]\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "    \n",
    "    I_m = jnp.eye(m)\n",
    "    I_k = jnp.eye(k)\n",
    "    I_n = jnp.eye(n)\n",
    "    \n",
    "    V = Vt.T\n",
    "    Ut = U.T\n",
    "    gUt = gU.T\n",
    "    gV = gVt.T\n",
    "    \n",
    "    S_inv = jnp.linalg.inv(S)\n",
    "    \n",
    "    F_ = F(S_vals, k)\n",
    "    \n",
    "    term_U = (U @ (F_ * (Ut @ gU - gUt @ U)) @ S + (I_m - U @ Ut) @ gU @ S_inv) @ Vt\n",
    "    \n",
    "    term_S = U @ (I_k * gS) @ Vt\n",
    "    \n",
    "    term_V = U @ (S @ (F_ * (Vt @ gV - gVt @ V)) @ Vt + S_inv @ gVt @ (I_n - V @ Vt))\n",
    "    \n",
    "    gA = term_U + term_S + term_V\n",
    "    \n",
    "    return gA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d6b9b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[-0.604877  ,  0.4115927 ,  0.2906126 ],\n",
       "             [ 0.369074  , -0.5303678 ,  0.9319923 ],\n",
       "             [ 0.78237915,  0.78433084, -0.0146427 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = jnp.array([[1., 2., 3.], [5., 4., 6.], [10., 9., 8.]])\n",
    "\n",
    "U, S, Vt = jnp.linalg.svd(A)\n",
    "\n",
    "gU = jnp.ones_like(U)\n",
    "gS = jnp.ones_like(S)\n",
    "gVt = jnp.ones_like(Vt)\n",
    "\n",
    "gA = svd_vjp_real_valued_partial(A, U, S, Vt, gU, gS, gVt)\n",
    "\n",
    "gA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72312621",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "SVD real differentiability:\n",
    "- https://j-towns.github.io/papers/svd-derivative.pdf\n",
    "- https://people.maths.ox.ac.uk/gilesm/files/NA-08-01.pdf\n",
    "- https://arxiv.org/pdf/1509.07838.pdf\n",
    "\n",
    "SVD complex differentiability:\n",
    "- https://arxiv.org/pdf/1909.02659.pdf\n",
    "- https://giggleliu.github.io/2019/04/02/einsumbp.html\n",
    "\n",
    "Existing implementations:\n",
    "\n",
    "Jax forward:\n",
    "- https://github.com/google/jax/blob/2a00533e3e686c1c9d7dfe9ed2a3b19217cfe76f/jax/_src/lax/linalg.py#L1578\n",
    "- Jax only implements the forward rule because jax can derive the backward rule from the forward rule and vice versa.\n",
    "\n",
    "Pytorch forward:\n",
    "- https://github.com/pytorch/pytorch/blob/7a8152530d490b30a56bb090e9a67397d20e16b1/torch/csrc/autograd/FunctionsManual.cpp#L3122\n",
    "\n",
    "Pytorch backward:\n",
    "- https://github.com/pytorch/pytorch/blob/7a8152530d490b30a56bb090e9a67397d20e16b1/torch/csrc/autograd/FunctionsManual.cpp#L3228\n",
    "\n",
    "Tensorflow forward:\n",
    "- https://github.com/tensorflow/tensorflow/blob/bbe41abdcb2f7e923489bfa21cfb546b6022f330/tensorflow/python/ops/linalg_grad.py#L815\n",
    "\n",
    "General complex differentiability:\n",
    "- https://mediatum.ub.tum.de/doc/631019/631019.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b9f6485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[1., 4.],\n",
       "              [2., 5.]], dtype=float32),\n",
       " DeviceArray([[1., 3., 0.],\n",
       "              [2., 4., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "def f(A, B):\n",
    "    return jnp.trace(A @ B)\n",
    "\n",
    "A = jnp.array([[1, 2], [3, 4]], dtype=float)\n",
    "B = jnp.array([[1,2,3], [4,5,6]], dtype=float)\n",
    "\n",
    "print(f(A, B))\n",
    "\n",
    "jax.jacfwd(f, argnums=(0, 1))(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3db5e403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.f_jvp(primals, tangents)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jax import custom_jvp\n",
    "import jax.numpy as jnp\n",
    "\n",
    "# f :: a -> b\n",
    "@custom_jvp\n",
    "def f(x):\n",
    "    return jnp.dot(x, x)\n",
    "\n",
    "# f_jvp :: (a, T a) -> (b, T b)\n",
    "def f_jvp(primals, tangents):\n",
    "    x, = primals\n",
    "    t, = tangents\n",
    "    return f(x), 2 * x @ t\n",
    "\n",
    "f.defjvp(f_jvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c648956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([2., 4., 8.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.grad(f)(jnp.array([1.,2.,4.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5e11376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22ma\u001b[35m:f32[3]\u001b[39m; b\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
       "    \u001b[39m\u001b[22m\u001b[22mc\u001b[35m:f32[3]\u001b[39m = dot_general[\n",
       "      dimension_numbers=(((), ()), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] b a\n",
       "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(c,) }"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.make_jaxpr(jax.vjp(f, jnp.array([1.,2.,3.]))[1])(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "810d1719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ \u001b[34m\u001b[22m\u001b[1mlambda \u001b[39m\u001b[22m\u001b[22ma\u001b[35m:f32[3]\u001b[39m; b\u001b[35m:f32[]\u001b[39m. \u001b[34m\u001b[22m\u001b[1mlet\n",
       "    \u001b[39m\u001b[22m\u001b[22mc\u001b[35m:f32[3]\u001b[39m = dot_general[\n",
       "      dimension_numbers=(((), ()), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] b a\n",
       "    d\u001b[35m:f32[3]\u001b[39m = dot_general[\n",
       "      dimension_numbers=(((), ()), ((), ()))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] b a\n",
       "    e\u001b[35m:f32[3]\u001b[39m = add_any d c\n",
       "  \u001b[34m\u001b[22m\u001b[1min \u001b[39m\u001b[22m\u001b[22m(e,) }"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.make_jaxpr(jax.vjp(lambda x: x @ x, jnp.array([1.,2.,3.]))[1])(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88158638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([2., 4., 6.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.jacrev(f)(jnp.array([1.,2.,3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f21988f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([2., 4., 6.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.jacrev(lambda x: x @ x)(jnp.array([1., 2., 3.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41a6958a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([2., 4.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * jnp.array([1.,2.])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
